{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression as lr\n",
    "from sklearn.model_selection import train_test_split as train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder as OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reading CSV file and separating X and y</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "insu = pd.read_csv('insurance.csv')\n",
    "X = insu[insu.columns[:-1]].copy()\n",
    "y = insu[insu.columns[-1]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preproccessing</h1>\n",
    "\n",
    "Using One Hot Encoding to convert features denoted as strings to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age     bmi  children  sex_ordinal  smoke_ordinal  northeast  northwest  \\\n",
      "0      19  27.900         0            0              1        0.0        0.0   \n",
      "1      18  33.770         1            1              0        0.0        0.0   \n",
      "2      28  33.000         3            1              0        0.0        0.0   \n",
      "3      33  22.705         0            1              0        0.0        1.0   \n",
      "4      32  28.880         0            1              0        0.0        1.0   \n",
      "...   ...     ...       ...          ...            ...        ...        ...   \n",
      "1333   50  30.970         3            1              0        0.0        1.0   \n",
      "1334   18  31.920         0            0              0        1.0        0.0   \n",
      "1335   18  36.850         0            0              0        0.0        0.0   \n",
      "1336   21  25.800         0            0              0        0.0        0.0   \n",
      "1337   61  29.070         0            0              1        0.0        1.0   \n",
      "\n",
      "      southeast  southwest  \n",
      "0           0.0        1.0  \n",
      "1           1.0        0.0  \n",
      "2           1.0        0.0  \n",
      "3           0.0        0.0  \n",
      "4           0.0        0.0  \n",
      "...         ...        ...  \n",
      "1333        0.0        0.0  \n",
      "1334        0.0        0.0  \n",
      "1335        1.0        0.0  \n",
      "1336        0.0        1.0  \n",
      "1337        0.0        0.0  \n",
      "\n",
      "[1338 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "Sex_dict = { \"female\":0,\n",
    "             \"male\":1 }\n",
    "\n",
    "X[\"sex_ordinal\"] = X.sex.map(Sex_dict)\n",
    "\n",
    "smoke_ordinal = { \"no\":0,\n",
    "             \"yes\":1 }\n",
    "\n",
    "X[\"smoke_ordinal\"] = X.smoker.map(smoke_ordinal)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(X[['region']])\n",
    "x_ohe = enc.transform(X[['region']]).toarray()\n",
    "\n",
    "new_cols = list(np.unique(X['region']))\n",
    "\n",
    "for i in range(len(new_cols)):\n",
    "    X[new_cols[i]] = x_ohe[:,i]  \n",
    "X.drop(columns = ['sex','smoker','region'],axis=0,inplace=True)\n",
    "print(X)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Splitting the dataset</h1>\n",
    "\n",
    "Splitting the dataset into : Training,Validation and Testing in an 80:10:10 proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=1)\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size=0.09,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape :  (1095, 9)\n",
      "Validation set shape :  (109, 9)\n",
      "Testing set shape :  (134, 9)\n"
     ]
    }
   ],
   "source": [
    "print('Training set shape : ',X_train.shape)\n",
    "print('Validation set shape : ',X_val.shape)\n",
    "print('Testing set shape : ',X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training the model on the training set </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_values():\n",
    "    gradient = np.ones((X_train.shape[1],1)) \n",
    "    b = 1\n",
    "    alpha = 0.01\n",
    "    m = X_train.shape[0]\n",
    "    y_t = np.array(y_train).reshape(m,1)\n",
    "\n",
    "    \n",
    "    return gradient,b,alpha,m,y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearRegressionTraining(epoch,X_train):\n",
    "    g,b,a,m,y_t = init_values()\n",
    "    dg = np.zeros((g.shape))\n",
    "    db = 0\n",
    "    X = X_train\n",
    "    jhist = []\n",
    "\n",
    "    for i in range(epoch):\n",
    "        h = np.dot(X,g) + b\n",
    "        j = np.sum(np.power( h-y_t,2 )  ) /(2*m)\n",
    "        u = np.multiply( h-y_t,X )\n",
    "        dg = np.array(np.sum(np.multiply( h-y_t,X ) , axis = 0 )/(m)).reshape(g.shape)\n",
    "        db = np.sum(h-y_t)/(m)\n",
    "        g= g - (a*dg)/m  \n",
    "        b = b - (a*db)/m\n",
    "        \n",
    "        print('The loss for iteration ',i+1,'is : ',j)\n",
    "        jhist.append(j)\n",
    "       \n",
    "    plt.plot(np.arange(1,epoch+1),jhist)        \n",
    "    return g,b    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of epochs :200\n",
      "The loss for iteration  1 is :  156545232.85758436\n",
      "The loss for iteration  2 is :  152164506.54944623\n",
      "The loss for iteration  3 is :  147990280.19490972\n",
      "The loss for iteration  4 is :  144012819.34094438\n",
      "The loss for iteration  5 is :  140222848.41893503\n",
      "The loss for iteration  6 is :  136611529.11276168\n",
      "The loss for iteration  7 is :  133170439.74661335\n",
      "The loss for iteration  8 is :  129891555.64446548\n",
      "The loss for iteration  9 is :  126767230.41541559\n",
      "The loss for iteration  10 is :  123790178.12123345\n",
      "The loss for iteration  11 is :  120953456.28453651\n",
      "The loss for iteration  12 is :  118250449.69796434\n",
      "The loss for iteration  13 is :  115674854.99659224\n",
      "The loss for iteration  14 is :  113220665.95760493\n",
      "The loss for iteration  15 is :  110882159.49294733\n",
      "The loss for iteration  16 is :  108653882.30228467\n",
      "The loss for iteration  17 is :  106530638.15514575\n",
      "The loss for iteration  18 is :  104507475.77258848\n",
      "The loss for iteration  19 is :  102579677.28012694\n",
      "The loss for iteration  20 is :  100742747.20498994\n",
      "The loss for iteration  21 is :  98992401.99205165\n",
      "The loss for iteration  22 is :  97324560.01398352\n",
      "The loss for iteration  23 is :  95735332.05233017\n",
      "The loss for iteration  24 is :  94221012.2273095\n",
      "The loss for iteration  25 is :  92778069.35518429\n",
      "The loss for iteration  26 is :  91403138.71304925\n",
      "The loss for iteration  27 is :  90093014.19182798\n",
      "The loss for iteration  28 is :  88844640.81917948\n",
      "The loss for iteration  29 is :  87655107.63487683\n",
      "The loss for iteration  30 is :  86521640.9020418\n",
      "The loss for iteration  31 is :  85441597.63840394\n",
      "The loss for iteration  32 is :  84412459.4524972\n",
      "The loss for iteration  33 is :  83431826.67042011\n",
      "The loss for iteration  34 is :  82497412.73946151\n",
      "The loss for iteration  35 is :  81607038.895541\n",
      "The loss for iteration  36 is :  80758629.08202727\n",
      "The loss for iteration  37 is :  79950205.10808465\n",
      "The loss for iteration  38 is :  79179882.03525645\n",
      "The loss for iteration  39 is :  78445863.78152555\n",
      "The loss for iteration  40 is :  77746438.93260099\n",
      "The loss for iteration  41 is :  77079976.75066118\n",
      "The loss for iteration  42 is :  76444923.37124608\n",
      "The loss for iteration  43 is :  75839798.17942882\n",
      "The loss for iteration  44 is :  75263190.35681523\n",
      "The loss for iteration  45 is :  74713755.59131888\n",
      "The loss for iteration  46 is :  74190212.94203793\n",
      "The loss for iteration  47 is :  73691341.85192253\n",
      "The loss for iteration  48 is :  73215979.30126572\n",
      "The loss for iteration  49 is :  72763017.09537947\n",
      "The loss for iteration  50 is :  72331399.28013034\n",
      "The loss for iteration  51 is :  71920119.67930736\n",
      "The loss for iteration  52 is :  71528219.54807892\n",
      "The loss for iteration  53 is :  71154785.33706649\n",
      "The loss for iteration  54 is :  70798946.56182006\n",
      "The loss for iteration  55 is :  70459873.77272739\n",
      "The loss for iteration  56 is :  70136776.62062193\n",
      "The loss for iteration  57 is :  69828902.01357868\n",
      "The loss for iteration  58 is :  69535532.36059882\n",
      "The loss for iteration  59 is :  69255983.89808792\n",
      "The loss for iteration  60 is :  68989605.09522383\n",
      "The loss for iteration  61 is :  68735775.13449633\n",
      "The loss for iteration  62 is :  68493902.4638743\n",
      "The loss for iteration  63 is :  68263423.4172241\n",
      "The loss for iteration  64 is :  68043800.89976177\n",
      "The loss for iteration  65 is :  67834523.13547336\n",
      "The loss for iteration  66 is :  67635102.47358203\n",
      "The loss for iteration  67 is :  67445074.25127883\n",
      "The loss for iteration  68 is :  67263995.71006428\n",
      "The loss for iteration  69 is :  67091444.963174134\n",
      "The loss for iteration  70 is :  66927020.01168087\n",
      "The loss for iteration  71 is :  66770337.80697633\n",
      "The loss for iteration  72 is :  66621033.357449144\n",
      "The loss for iteration  73 is :  66478758.877273716\n",
      "The loss for iteration  74 is :  66343182.97532535\n",
      "The loss for iteration  75 is :  66213989.88233024\n",
      "The loss for iteration  76 is :  66090878.71444769\n",
      "The loss for iteration  77 is :  65973562.77156723\n",
      "The loss for iteration  78 is :  65861768.868684314\n",
      "The loss for iteration  79 is :  65755236.69879501\n",
      "The loss for iteration  80 is :  65653718.22582396\n",
      "The loss for iteration  81 is :  65556977.10616997\n",
      "The loss for iteration  82 is :  65464788.137519985\n",
      "The loss for iteration  83 is :  65376936.73364612\n",
      "The loss for iteration  84 is :  65293218.423960954\n",
      "The loss for iteration  85 is :  65213438.37666382\n",
      "The loss for iteration  86 is :  65137410.94436609\n",
      "The loss for iteration  87 is :  65064959.23113589\n",
      "The loss for iteration  88 is :  64995914.67995232\n",
      "The loss for iteration  89 is :  64930116.679607235\n",
      "The loss for iteration  90 is :  64867412.19013775\n",
      "The loss for iteration  91 is :  64807655.38591599\n",
      "The loss for iteration  92 is :  64750707.315563545\n",
      "The loss for iteration  93 is :  64696435.57789793\n",
      "The loss for iteration  94 is :  64644714.0131545\n",
      "The loss for iteration  95 is :  64595422.408764854\n",
      "The loss for iteration  96 is :  64548446.21900437\n",
      "The loss for iteration  97 is :  64503676.29785603\n",
      "The loss for iteration  98 is :  64461008.6444668\n",
      "The loss for iteration  99 is :  64420344.16060345\n",
      "The loss for iteration  100 is :  64381588.419541895\n",
      "The loss for iteration  101 is :  64344651.445851184\n",
      "The loss for iteration  102 is :  64309447.50555844\n",
      "The loss for iteration  103 is :  64275894.90620555\n",
      "The loss for iteration  104 is :  64243915.806331255\n",
      "The loss for iteration  105 is :  64213436.03393418\n",
      "The loss for iteration  106 is :  64184384.91349373\n",
      "The loss for iteration  107 is :  64156695.10114502\n",
      "The loss for iteration  108 is :  64130302.427623995\n",
      "The loss for iteration  109 is :  64105145.74861592\n",
      "The loss for iteration  110 is :  64081166.80215861\n",
      "The loss for iteration  111 is :  64058310.07276755\n",
      "The loss for iteration  112 is :  64036522.66196646\n",
      "The loss for iteration  113 is :  64015754.164920785\n",
      "The loss for iteration  114 is :  63995956.55288685\n",
      "The loss for iteration  115 is :  63977084.06120249\n",
      "The loss for iteration  116 is :  63959093.082557574\n",
      "The loss for iteration  117 is :  63941942.06529607\n",
      "The loss for iteration  118 is :  63925591.41651188\n",
      "The loss for iteration  119 is :  63910003.40971301\n",
      "The loss for iteration  120 is :  63895142.09683838\n",
      "The loss for iteration  121 is :  63880973.22442217\n",
      "The loss for iteration  122 is :  63867464.15371013\n",
      "The loss for iteration  123 is :  63854583.7845418\n",
      "The loss for iteration  124 is :  63842302.48282081\n",
      "The loss for iteration  125 is :  63830592.01140421\n",
      "The loss for iteration  126 is :  63819425.46424994\n",
      "The loss for iteration  127 is :  63808777.203668185\n",
      "The loss for iteration  128 is :  63798622.80053117\n",
      "The loss for iteration  129 is :  63788938.97730115\n",
      "The loss for iteration  130 is :  63779703.55374421\n",
      "The loss for iteration  131 is :  63770895.395203166\n",
      "The loss for iteration  132 is :  63762494.36330873\n",
      "The loss for iteration  133 is :  63754481.2690144\n",
      "The loss for iteration  134 is :  63746837.827845044\n",
      "The loss for iteration  135 is :  63739546.61725529\n",
      "The loss for iteration  136 is :  63732591.03599795\n",
      "The loss for iteration  137 is :  63725955.26540774\n",
      "The loss for iteration  138 is :  63719624.232510306\n",
      "The loss for iteration  139 is :  63713583.574870184\n",
      "The loss for iteration  140 is :  63707819.60709571\n",
      "The loss for iteration  141 is :  63702319.288923204\n",
      "The loss for iteration  142 is :  63697070.194805324\n",
      "The loss for iteration  143 is :  63692060.48493328\n",
      "The loss for iteration  144 is :  63687278.87762501\n",
      "The loss for iteration  145 is :  63682714.6230149\n",
      "The loss for iteration  146 is :  63678357.47798388\n",
      "The loss for iteration  147 is :  63674197.682271264\n",
      "The loss for iteration  148 is :  63670225.93571273\n",
      "The loss for iteration  149 is :  63666433.37655121\n",
      "The loss for iteration  150 is :  63662811.56077033\n",
      "The loss for iteration  151 is :  63659352.442402\n",
      "The loss for iteration  152 is :  63656048.35476236\n",
      "The loss for iteration  153 is :  63652891.99257219\n",
      "The loss for iteration  154 is :  63649876.394920245\n",
      "The loss for iteration  155 is :  63646994.92902969\n",
      "The loss for iteration  156 is :  63644241.27478975\n",
      "The loss for iteration  157 is :  63641609.41001658\n",
      "The loss for iteration  158 is :  63639093.596408874\n",
      "The loss for iteration  159 is :  63636688.366165705\n",
      "The loss for iteration  160 is :  63634388.50923494\n",
      "The loss for iteration  161 is :  63632189.06116297\n",
      "The loss for iteration  162 is :  63630085.29151718\n",
      "The loss for iteration  163 is :  63628072.69285412\n",
      "The loss for iteration  164 is :  63626146.970207684\n",
      "The loss for iteration  165 is :  63624304.031073\n",
      "The loss for iteration  166 is :  63622539.975862324\n",
      "The loss for iteration  167 is :  63620851.08881083\n",
      "The loss for iteration  168 is :  63619233.82931126\n",
      "The loss for iteration  169 is :  63617684.823656864\n",
      "The loss for iteration  170 is :  63616200.85717375\n",
      "The loss for iteration  171 is :  63614778.86672402\n",
      "The loss for iteration  172 is :  63613415.93356235\n",
      "The loss for iteration  173 is :  63612109.27652924\n",
      "The loss for iteration  174 is :  63610856.24556528\n",
      "The loss for iteration  175 is :  63609654.31553096\n",
      "The loss for iteration  176 is :  63608501.0803181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss for iteration  177 is :  63607394.247238435\n",
      "The loss for iteration  178 is :  63606331.63167722\n",
      "The loss for iteration  179 is :  63605311.15199847\n",
      "The loss for iteration  180 is :  63604330.824690655\n",
      "The loss for iteration  181 is :  63603388.75974096\n",
      "The loss for iteration  182 is :  63602483.15622784\n",
      "The loss for iteration  183 is :  63601612.29812121\n",
      "The loss for iteration  184 is :  63600774.55028056\n",
      "The loss for iteration  185 is :  63599968.35464207\n",
      "The loss for iteration  186 is :  63599192.22658488\n",
      "The loss for iteration  187 is :  63598444.751469165\n",
      "The loss for iteration  188 is :  63597724.581337236\n",
      "The loss for iteration  189 is :  63597030.43177\n",
      "The loss for iteration  190 is :  63596361.078891896\n",
      "The loss for iteration  191 is :  63595715.35651674\n",
      "The loss for iteration  192 is :  63595092.15342834\n",
      "The loss for iteration  193 is :  63594490.41078911\n",
      "The loss for iteration  194 is :  63593909.11967102\n",
      "The loss for iteration  195 is :  63593347.31870285\n",
      "The loss for iteration  196 is :  63592804.09182823\n",
      "The loss for iteration  197 is :  63592278.5661697\n",
      "The loss for iteration  198 is :  63591769.9099931\n",
      "The loss for iteration  199 is :  63591277.3307681\n",
      "The loss for iteration  200 is :  63590800.073320195\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = int(input('Enter the number of epochs :'))\n",
    "G,B = linearRegressionTraining(epochs,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_val = np.dot(X_val,G) + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67862787.37128407\n"
     ]
    }
   ],
   "source": [
    "Y = np.array(y_val).reshape(y_val.shape[0],1)\n",
    "mse = np.mean(np.power(h_val-Y,2))/2\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.54010409e+04  1.04229166e+04  4.77613356e+01]\n",
      " [ 1.69716821e+04  1.17358790e+04  4.46136415e+01]\n",
      " [ 1.36245027e+04  6.57154400e+03  1.07325748e+02]\n",
      " [ 1.54937671e+04  7.65077375e+03  1.02512421e+02]\n",
      " [ 1.42992856e+04  8.23309750e+03  7.36805083e+01]\n",
      " [ 1.49461466e+04  1.10137119e+04  3.57048989e+01]\n",
      " [ 1.50511620e+04  8.70345600e+03  7.29331660e+01]\n",
      " [ 1.33267359e+04  4.01822460e+04 -6.68342683e+01]\n",
      " [ 7.26276952e+03  1.24226000e+03  4.84641663e+02]\n",
      " [ 1.37513536e+04  4.00033322e+04 -6.56244798e+01]\n",
      " [ 9.76609764e+03  4.71973655e+03  1.06920398e+02]\n",
      " [ 7.58229224e+03  1.70562450e+03  3.44546396e+02]\n",
      " [ 1.60592878e+04  1.12993430e+04  4.21258549e+01]\n",
      " [ 1.16178696e+04  3.61976990e+04 -6.79043975e+01]\n",
      " [ 1.39018563e+04  2.62365800e+04 -4.70134587e+01]\n",
      " [ 1.54938042e+04  6.35627070e+03  1.43756204e+02]\n",
      " [ 1.39709793e+04  6.07967150e+03  1.29798260e+02]\n",
      " [ 1.31538854e+04  5.98952365e+03  1.19614884e+02]\n",
      " [ 1.00553290e+04  3.16145400e+03  2.18060267e+02]\n",
      " [ 1.41472350e+04  8.21920390e+03  7.21241518e+01]\n",
      " [ 9.09047837e+03  1.81587590e+03  4.00611213e+02]\n",
      " [ 1.07166919e+04  3.48388730e+04 -6.92392694e+01]\n",
      " [ 1.91205298e+04  3.16200011e+04 -3.95302684e+01]\n",
      " [ 7.32556973e+03  2.80369785e+03  1.61282425e+02]\n",
      " [ 1.87055506e+04  4.72910550e+04 -6.04459013e+01]\n",
      " [ 1.03328212e+04  2.01776711e+04 -4.87908135e+01]\n",
      " [ 1.56901609e+04  9.37790470e+03  6.73098783e+01]\n",
      " [ 8.46288985e+03  1.88387037e+04 -5.50771114e+01]\n",
      " [ 1.22213695e+04  8.96579575e+03  3.63110407e+01]\n",
      " [ 1.27831577e+04  6.55175010e+03  9.51105819e+01]\n",
      " [ 1.26422700e+04  6.40641070e+03  9.73378011e+01]\n",
      " [ 9.89627099e+03  4.61807990e+03  1.14294062e+02]\n",
      " [ 1.49063889e+04  4.21245153e+04 -6.46135064e+01]\n",
      " [ 1.65737647e+04  9.85043200e+03  6.82541910e+01]\n",
      " [ 1.47829169e+04  1.00654130e+04  4.68684587e+01]\n",
      " [ 8.35371740e+03  2.73191220e+03  2.05782792e+02]\n",
      " [ 1.41187268e+04  2.19786769e+04 -3.57617071e+01]\n",
      " [ 1.76021779e+04  1.05797110e+04  6.63767364e+01]\n",
      " [ 1.12989408e+04  5.32565100e+03  1.12160745e+02]\n",
      " [ 1.13666429e+04  3.65934600e+03  2.10619517e+02]\n",
      " [ 7.52290251e+03  1.71102680e+03  3.39671811e+02]\n",
      " [ 1.71649141e+04  1.19871682e+04  4.31940708e+01]\n",
      " [ 9.04010190e+03  1.90635825e+03  3.74207925e+02]\n",
      " [ 1.90966421e+04  4.68892612e+04 -5.92728877e+01]\n",
      " [ 1.16203955e+04  4.09041995e+04 -7.15911920e+01]\n",
      " [ 1.10076617e+04  5.03126955e+03  1.18784973e+02]\n",
      " [ 8.82012395e+03  2.25747525e+03  2.90707448e+02]\n",
      " [ 1.08615128e+04  5.45804645e+03  9.90000067e+01]\n",
      " [ 1.32034559e+04  8.42806930e+03  5.66605045e+01]\n",
      " [ 9.62451129e+03  2.60189505e+04 -6.30096099e+01]\n",
      " [ 1.18293603e+04  6.11749450e+03  9.33693663e+01]\n",
      " [ 1.71539274e+04  9.88006800e+03  7.36215516e+01]\n",
      " [ 1.44830742e+04  2.30654207e+04 -3.72087145e+01]\n",
      " [ 1.26233050e+04  2.04206047e+04 -3.81834906e+01]\n",
      " [ 1.13565526e+04  1.90408760e+04 -4.03569847e+01]\n",
      " [ 1.42969408e+04  9.71584100e+03  4.71508315e+01]\n",
      " [ 1.29125884e+04  1.95155416e+04 -3.38343322e+01]\n",
      " [ 1.62157811e+04  1.05604917e+04  5.35513837e+01]\n",
      " [ 1.29760831e+04  5.72900530e+03  1.26498013e+02]\n",
      " [ 1.39288390e+04  6.35877645e+03  1.19049043e+02]\n",
      " [ 8.77509732e+03  3.33075508e+04 -7.36543303e+01]\n",
      " [ 9.78710988e+03  5.20957885e+03  8.78675832e+01]\n",
      " [ 1.67736273e+04  8.94411510e+03  8.75381421e+01]\n",
      " [ 1.06693331e+04  4.50033925e+03  1.37078419e+02]\n",
      " [ 1.70463561e+04  1.18407751e+04  4.39631784e+01]\n",
      " [ 1.49129894e+04  5.66222500e+03  1.63376842e+02]\n",
      " [ 1.66378777e+04  2.73227339e+04 -3.91061018e+01]\n",
      " [ 1.99854920e+04  1.43190310e+04  3.95729359e+01]\n",
      " [ 1.67475626e+04  1.31126048e+04  2.77210963e+01]\n",
      " [ 8.77995177e+03  2.39609590e+03  2.66427394e+02]\n",
      " [ 9.57807081e+03  4.87798105e+03  9.63531780e+01]\n",
      " [ 1.47990158e+04  2.61403603e+04 -4.33863359e+01]\n",
      " [ 8.67682356e+03  2.39517155e+03  2.62263136e+02]\n",
      " [ 1.30322888e+04  5.48826200e+03  1.37457484e+02]\n",
      " [ 1.37622698e+04  6.18612700e+03  1.22469887e+02]\n",
      " [ 1.43131531e+04  4.37533371e+04 -6.72867166e+01]\n",
      " [ 1.59965118e+04  1.09593300e+04  4.59624981e+01]\n",
      " [ 1.95881447e+04  4.95776624e+04 -6.04899793e+01]\n",
      " [ 1.54411337e+04  1.20323260e+04  2.83304134e+01]\n",
      " [ 1.39812631e+04  1.00969700e+04  3.84698885e+01]\n",
      " [ 1.56331034e+04  1.06005483e+04  4.74744790e+01]\n",
      " [ 1.39092839e+04  8.26904400e+03  6.82090931e+01]\n",
      " [ 1.46254240e+04  7.26570250e+03  1.01294012e+02]\n",
      " [ 1.23135886e+04  5.13825670e+03  1.39645259e+02]\n",
      " [ 1.52394008e+04  6.43562370e+03  1.36797574e+02]\n",
      " [ 1.64663263e+04  4.19995200e+04 -6.07940131e+01]\n",
      " [ 7.78453043e+03  2.19647320e+03  2.54410445e+02]\n",
      " [ 8.36672115e+03  2.68094930e+03  2.12080544e+02]\n",
      " [ 1.37429942e+04  2.21440320e+04 -3.79381576e+01]\n",
      " [ 1.51871071e+04  1.10855868e+04  3.69986760e+01]\n",
      " [ 1.32918921e+04  3.98984100e+03  2.33143404e+02]\n",
      " [ 1.63320033e+04  9.87270100e+03  6.54258883e+01]\n",
      " [ 1.22511534e+04  6.27247720e+03  9.53160297e+01]\n",
      " [ 1.70303774e+04  1.18424420e+04  4.38079867e+01]\n",
      " [ 7.74929336e+03  1.96478000e+03  2.94410232e+02]\n",
      " [ 8.83517397e+03  3.43031672e+04 -7.42438536e+01]\n",
      " [ 1.02629078e+04  1.91731840e+03  4.35274045e+02]\n",
      " [ 1.14097534e+04  5.26146945e+03  1.16854883e+02]\n",
      " [ 1.23947945e+04  4.67064000e+03  1.65376790e+02]\n",
      " [ 1.26639238e+04  1.95948096e+04 -3.53710294e+01]\n",
      " [ 1.54379166e+04  1.01150089e+04  5.26238561e+01]\n",
      " [ 1.88584745e+04  1.51615344e+04  2.43836803e+01]\n",
      " [ 1.72526125e+04  1.18426238e+04  4.56823495e+01]\n",
      " [ 1.32730442e+04  3.97742763e+04 -6.66290743e+01]\n",
      " [ 1.40139019e+04  4.53625900e+03  2.08930816e+02]\n",
      " [ 1.49552336e+04  6.47401300e+03  1.31004071e+02]\n",
      " [ 1.59360811e+04  9.86981020e+03  6.14628935e+01]\n",
      " [ 1.76498789e+04  1.32240570e+04  3.34679581e+01]\n",
      " [ 1.99135181e+04  1.44182804e+04  3.81129894e+01]]\n"
     ]
    }
   ],
   "source": [
    "percentage_error = 100 * np.divide(h_val-Y,Y) \n",
    "comp = np.concatenate((h_val,Y,percentage_error), axis = 1)\n",
    "print(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
